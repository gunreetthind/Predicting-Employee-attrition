---
title: "Regis Stylist Attrition"
author: "Carlson MSBA Team"
date: "April 3, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Installing the necessary libraries:

```{r}
suppressPackageStartupMessages({
  library(Amelia)
  library(caret)
  library(dplyr)
  library(ROCR)
  library(pROC)
  library(C50)
  library(car)
  library(mlbench)
  library(e1071)
  library(AUC)
  library(ROSE)
  library(lme4)
  library(broom)
  library(earth)
  library(foreign)
  library(ggplot2)
  library(glmnet)
  library(cluster)
})

```

Read in the data:
```{r}
data1 = read.csv('Load data', 
                 header=TRUE, stringsAsFactors = FALSE)
names(data1)[1]<-"EmployeeKey"
```

Treatment of the data
```{r}
# Removing null values
data1 <- data1 %>%
  filter(TotalWage != 'NULL', TotalHours != 'NULL', TotalSales != 'NULL',
         TotalTip != 'NULL', WageLast6Weeks != 'NULL', Tenure_in_days >= 0)

data1$Tenure_in_days[data1$Tenure_in_days==0] = 1
data1 <- data1[!data1$Division == "Trade Secret",]

# Changing data type of variables
data1$TotalWage<-as.numeric(data1$TotalWage)
data1$TotalHours<-as.numeric(data1$TotalHours)
data1$TotalSales<-as.numeric(data1$TotalSales)
data1$Tenure_in_days<-as.numeric(data1$Tenure_in_days)
data1$Age <- as.integer(data1$Age)
data1$Stylist_is_Active <- as.factor(data1$Stylist_is_Active)
data1$Division <- as.factor(data1$Division)
data1$TopStylist <- as.numeric(data1$TopStylist)
data1$NumberOfTerminations <- as.numeric(data1$NumberOfTerminations)
data1$TotalGap <- as.numeric(data1$TotalGap)
data1$ReHireFlag <- as.factor(data1$ReHireFlag)
data1$DeductionFlag <- as.factor(data1$DeductionFlag)
data1$TotalTip <- as.numeric(as.character(data1$TotalTip))
data1$HoursLast6Weeks <- as.numeric(data1$HoursLast6Weeks)
data1$WageLast6Weeks <- as.numeric(data1$WageLast6Weeks)

# Defining new variables for Hourly metrics
data1$HourlyTip <- as.numeric(data1$TotalTip)/as.numeric(data1$TotalHours)
data1$hourlywage_6weeks <- as.numeric(data1$WageLast6Weeks)/as.numeric(data1$HoursLast6Weeks)
data1$HourlySales = as.numeric(data1$TotalSales)/as.numeric(data1$TotalHours)
data1$HourlyWage = as.numeric(data1$TotalWage)/as.numeric(data1$TotalHours)
data1$WeeklyHours_Last6Weeks <- as.numeric(data1$HoursLast6Weeks)/6
data1$WeeklyHours <- as.numeric(7 * data1$TotalHours)/as.numeric(data1$Tenure_in_days)
data1$PctTopStylist = as.numeric(data1$TopStylist)/as.numeric(data1$Tenure_in_days)
data1$Churn = as.factor(ifelse(data1$Stylist_is_Active == 0, 1, 0))
data1 = na.omit(data1)

# Removing outliers
dat1 <- data1 %>%
  filter(Age > 0, Tenure_in_days > 0, TotalHours > 1, 
         TotalSales > 0,HourlyTip >= 0, hourlywage_6weeks >= 0) %>%
  filter(PctTopStylist <= 1, 
         HourlySales <= quantile(data1$HourlySales, 0.75) + 3*IQR(data1$HourlySales), 
         HourlyWage <= quantile(data1$HourlyWage, 0.75) + 3*IQR(data1$HourlyWage),
         hourlywage_6weeks <= quantile(data1$hourlywage_6weeks, 0.75) + 3*IQR(data1$hourlywage_6weeks),
         WeeklyHours <= quantile(data1$WeeklyHours, 0.75) +3*IQR(data1$WeeklyHours),
         WeeklyHours_Last6Weeks <= quantile(data1$WeeklyHours_Last6Weeks, 0.75) + 3*IQR(data1$WeeklyHours_Last6Weeks))

# Normalizing the variables using z-scores

dat1$z_sales <- as.numeric(scale(dat1$HourlySales, center=TRUE, scale = TRUE))
dat1$z_tenure <- as.numeric(scale(dat1$Tenure_in_days, center=TRUE, scale = TRUE))
dat1$z_gap <- as.numeric(scale(dat1$TotalGap, center=TRUE, scale = TRUE))
dat1$z_topstylist <- as.numeric(scale(dat1$PctTopStylist, center=TRUE, scale = TRUE))
dat1$z_numberofterminations <- as.numeric(scale(dat1$NumberOfTerminations, center=TRUE, scale = TRUE))
dat1$z_wage <- as.numeric(scale(dat1$HourlyWage, center=TRUE, scale = TRUE))
dat1$z_age <- as.numeric(scale(dat1$Age, center=TRUE, scale = TRUE))
dat1$z_tip <- as.numeric(scale(dat1$HourlyTip, center=TRUE, scale = TRUE))
dat1$z_6weekswage <- as.numeric(scale(dat1$hourlywage_6weeks, center=TRUE, scale = TRUE))
dat1$z_weeklyhours <- as.numeric(scale(dat1$WeeklyHours, center=TRUE, scale = TRUE))
dat1$z_weeklyhours_last6weeks <- as.numeric(scale(dat1$WeeklyHours_Last6Weeks, center=TRUE, scale = TRUE))

```

Clustering
```{r}
cluster_data <- dat1 %>% 
  select(EmployeeKey, Age, Tenure_in_days, PctTopStylist) 

#Normalization using Min-Max
normalize <- function(x)(x-min(x))/(max(x) - min(x))
scaled_data <- data.frame(apply(cluster_data[2:4], 2, normalize))

#Fit the model 
#Average Silhouette Width.38
set.seed(12345)
fit <- clara(scaled_data,6, samples = 1000, metric = "euclidean",  pamLike = TRUE)
summary(fit)

fit$medoids
fit$clusinfo

#Combine the clustering result
dat1$cluster <- fit$clustering

#Stats summary across clusters
results <- dat1 %>% 
  group_by(cluster) %>%
  select(Age,Tenure_in_days,PctTopStylist) %>%
  do(the_summary = summary(.)) %>%
  ungroup(cluster)

results$the_summary

#Check the row number of medoids 
#45217 24365 29584 57918 35366 26399
fit$i.med

#Inspect the medoids
dat1[c(45217,24365,29584,57918,35366,26399),] %>% 
  select(EmployeeKey,Age, Tenure_in_days, PctTopStylist)

```


##Logistic Model & Reason for churn for each cluster

```{r}

test_all <- data.frame(NULL)
reason_all <- data.frame(NULL)
dat1$Churn <- as.factor(dat1$Churn)

# Run a loop for each of the 6 clusters
for(i in 1:6){
  cd <- dat1 %>%
    filter(cluster == i) %>%
    select(EmployeeKey, Division, ReHireFlag,Tenure_in_days,TotalGap,PctTopStylist, 
           HourlySales,HourlyWage,HourlyTip,DeductionFlag,hourlywage_6weeks, WeeklyHours,
           WeeklyHours_Last6Weeks,cluster, z_tenure, z_gap, z_topstylist, z_sales, z_wage, z_tip, 
           z_age, z_6weekswage, z_weeklyhours, z_weeklyhours_last6weeks, Churn)
  
  cd$Churn <- as.factor(cd$Churn)
  
  # Create training and test sets
  Train <- createDataPartition(cd$Churn, p=0.8, list=FALSE)
  train <- cd[ Train, ]
  test <- cd[-Train, ]
  
  # Use a 5-fold cross validation
  cv <- trainControl(method = "cv", number = 5)
  
  # Logistic Regression Model 
  model_fit <- train(Churn ~ Division + ReHireFlag + DeductionFlag + z_sales + z_tenure +  
                       z_weeklyhours + z_gap + z_topstylist + z_age + z_tip + 
                       z_6weekswage + z_weeklyhours_last6weeks,
                      data = train, method = "glm", family = 'binomial', trControl = cv)
  
  print(summary(model_fit))
  
  # Predict Churn & Probability of Churn for test set
  pred_prob <- predict(model_fit, test, type = "prob")
  #pred <- predict(model_fit, test)
  
  test$prob_of_churn <- pred_prob$`1`
  test$prob_of_not_churn <- pred_prob$`0`
  test$prediction <- ifelse(test$prob_of_churn >= 0.70, 1, 0)
  
  test_all <- rbind(test_all, test)
  
  # Predict Churn & Probability of Churn for entire dataset
  pred_prob_cd <- predict(model_fit, cd, type = "prob")
  pred_cd <- predict(model_fit, cd)
  
  cd$prob_of_churn <- pred_prob_cd$`1`
  cd$prob_of_not_churn <- pred_prob_cd$`0`
  cd$prediction <- pred_cd
  
  # Store Model co-efficients into a separate data frame 
  datOut <- as.data.frame(summary(model_fit)$coef)
  datOut <- cbind(term = rownames(datOut), datOut)
  rownames(datOut) <- NULL
  
  datOut <- t(datOut[, 1:ncol(datOut)])
  colnames(datOut) <- datOut[1,]
  datOut <- datOut[-1,]
  datOut <- as.data.frame(datOut)

  for(i in c(1:ncol(datOut))){
    datOut[,i] <- as.numeric(as.character(datOut[,i]))
  }
  
  # Retain only significant variables
  datOut <- datOut[,!(datOut[4,] > 0.05)]
  head(datOut)
  
  # Create dummy variables for each variable
  dummies <- dummyVars(Churn ~ ., data = cd)
  dummies1 <- predict(dummies, newdata = cd)
  final_dummies <- as.data.frame(dummies1)
  dummy_temp <- final_dummies
  
  # Multiply coefficients with values for each employee to obtain reason for churn 
  for(i in 1:nrow(final_dummies)){
    if("DivisionNHC" %in% colnames(datOut)){
      final_dummies$Division_NHC[i] = datOut$DivisionNHC[1]*final_dummies$Division.NHC[i]}
  
    if("DivisionPromenade" %in% colnames(datOut)){
      final_dummies$Division_Promenade[i] = 
        datOut$DivisionPromenade[1]*final_dummies$Division.Promenade[i]}
  
    if("DivisionMasterCuts" %in% colnames(datOut)){
      final_dummies$Division_MasterCuts[i] = 
        datOut$DivisionMasterCuts[1]*final_dummies$Division.MasterCuts[i]}
  
    if("DivisionRegis" %in% colnames(datOut)){
      final_dummies$Division_Regis[i]= datOut$DivisionRegis[1]*final_dummies$Division.Regis[i]}
  
    if("DivisionSupercuts" %in% colnames(datOut)){
      final_dummies$Division_Supercuts[i] = 
        datOut$DivisionSupercuts[1]*final_dummies$Division.Supercuts[i]}
    
    if("z_weeklyhours" %in% colnames(datOut)){
      final_dummies$weeklyHours[i] = datOut$z_weeklyhours[1]*final_dummies$z_weeklyhours[i]}
    
    if("z_weeklyhours_last6weeks" %in% colnames(datOut)){
      final_dummies$weeklyHours_6weeks[i] = datOut$z_weeklyhours_last6weeks[1]*final_dummies$z_weeklyhours_last6weeks[i]}
  
    if("z_topstylist" %in% colnames(datOut)){
      final_dummies$topstylist_proportion[i] = datOut$z_topstylist[1]*final_dummies$z_topstylist[i]}
  
    if("z_gap" %in% colnames(datOut)){
      final_dummies$gap[i] = datOut$z_gap[1]*final_dummies$z_gap[i]}
  
    if("z_tenure" %in% colnames(datOut)){
      final_dummies$tenure[i] = datOut$z_tenure[1]*final_dummies$z_tenure[i]}
  
    if("DeductionFlag1" %in% colnames(datOut)){
      final_dummies$Deductionflag1[i] = datOut$DeductionFlag1[1]*final_dummies$DeductionFlag.1[i]}
  
    if("z_wage" %in% colnames(datOut)){
      final_dummies$wage[i] = datOut$z_wage[1]*final_dummies$z_wage[i]}
  
    if("z_6weekswage" %in% colnames(datOut)){
      final_dummies$wage_6_weeks[i] = datOut$z_6weekswage[1]*final_dummies$z_6weekswage[i]}
  
    if("z_age" %in% colnames(datOut)){
      final_dummies$age_of_stylist[i] = datOut$z_agege[1]*final_dummies$z_agege[i]}
  
    if("z_sales" %in% colnames(datOut)){
      final_dummies$sales[i] = datOut$z_sales[1]*final_dummies$z_sales[i]}
  
    if("z_tip" %in% colnames(datOut)){
      final_dummies$tip[i] = datOut$z_tip[1]*final_dummies$z_tip[i]}
  }
  
  # Determine top 3 reasons
  final_weight <- final_dummies[,(ncol(dummy_temp)+1):(ncol(final_dummies))]
  final_weight$reason1_for_churn <- colnames(final_weight)[apply(final_weight,1,which.max)]
  final_weight$reason2_for_churn <- 
    colnames(final_weight)[apply(final_weight[,1:(ncol(final_weight)-1)], 1, 
                                 function(x)which(x != 0 & x == sort(x, decreasing = TRUE)[2])[1])]
  
  final_weight$reason3_for_churn <-  
    colnames(final_weight)[apply(final_weight[,1:(ncol(final_weight)-2)], 1, 
                                 function(x)which(x != 0 & x == sort(x, decreasing = TRUE)[3])[1])]
  
  final_weight$reason1_weight <- apply(final_weight[,1:(ncol(final_weight)-3)], 1, max)
  final_weight$reason2_weight <- apply(final_weight[,1:(ncol(final_weight)-4)], 1, 
                                       FUN = function(x) tail(sort(x), 2)[1])
  final_weight$reason3_weight <- apply(final_weight[,1:(ncol(final_weight)-5)], 1, 
                                       FUN = function(x) tail(sort(x), 3)[1])
  
  final_weight$R1R2_relativeimpact <- ifelse(final_weight$reason2_weight == 0, NA, 
                          round(final_weight$reason1_weight,2)/round(final_weight$reason2_weight,2))
  
  final_weight$R1R3_relativeimpact <- ifelse(final_weight$reason3_weight==0, NA,                                            round(final_weight$reason1_weight,2)/round(final_weight$reason3_weight,2))
  
  reason_Output <- cbind(cd[1:14],
                         cd[,(ncol(test)-3):ncol(test)],
                         final_weight[,(ncol(final_weight)-7):(ncol(final_weight)-5)],
                         R1R2_Ratio = final_weight[,ncol(final_weight) - 1],
                         R1R3_Ratio = final_weight[,ncol(final_weight)])
  
  reason_all <- rbind(reason_all, reason_Output)
}

# Confusion matrix to see performance of the model 
confusionMatrix(test_all$prediction, test_all$Churn, 
                dnn = c('Predicted', 'Actual'), positive = '1')

# Arrange in descending order of probability of churning
reason_all <- arrange(reason_all, desc(prob_of_churn))

# Write the reasons into a CSV file
write.csv(reason_all, "Write data")

```

